---
title: How It Works
language: en
slug: how_it_works
---
<p>The purpose of FuTRES is to make individual-level trait data findable, accessible, interoperable, and reuseable. We serve trait data from biological and paleontological specimens in a format that is standardized. The datastore uses an ontological backbone to improve discoverability and promotes novel research. Here is a <a href="https://youtu.be/r2LNKU9hQEE">quick introduction to FuTRES</a>.<p>

<p><figure><img src="/media/FuTRESworkflow.png"/></figure></p>

<h1><img src="/media/pipelineIcon.png"
width="100"
style="float:left;">

# Data Pipeline 

<p>The data processing pipeline is comprised of five main steps: pre-processing, triplifying, reasoning, conversion to a tabular format, and data loading. For more information, you can watch this short video on the <a href="https://www.youtube.com/watch?v=tn_Rf9CQX3Y"><strong>FOVT Data Pipeline</strong></a>.</p>

<p>The pre-processing step is to help with data standardization. The template (below) helps users format their data. We have also created a <a href="https://futres.shinyapps.io/pyConvApp/">RShiny App</a> to help users format their data.
 
<p>After pre-processing, RDF triples are generated by reading configuration files from each data source that includes term mappings, data validation, and creating relationships between processes and objects as defined by the ontology. All triples are referenced by globally unique identifiers by appending record identifiers from the input data to globally unique, resolvable HTTP prefixes that can be customized for each project. Because instance identifiers are derived from the input data, output identifiers can be linked back to the specific records in the raw source data, which also provides a mechanism to track data provenance.</p>

<p>The next step in the workflow - reasoning - uses the bundled <a href="https://github.com/INCATools/ontology-development-kit">Ontology Development Kit</a> that supports multiple description logic profiles through multiple reasoners. The workflow provides an optional configuration file to OntoPilot that further allows users to customize the reasoning process. The reasoning helps with more flexible searches; for example, searching for "length" will provide all the length terms from the ontology that are in the FuTRES datastore.</p>

<p>The reformatting workflow converts the data to a series of CSV files via a customizable SPARQL query through <a href="https://github.com/biocodellc/query_fetcher">query_fetcher</a>, a bundled package for fast conversion of RDF to tabular data that is built upon the <a href="https://jena.apache.org/index.html">Apache Jena Java Library</a>. The output data can be loaded into whatever data storage system the user prefers, including key/value stores (e.g., ElasticSearch), relational databases (e.g., PostgreSQL), or triplestores (e.g., Blazegraph).
  
<h1><img src="/media/templateIcon.png"
width="100"
style="float:left;">

## Pre-processing
  
### Template
  
<p>We have developed a template (<a href="https://github.com/futres/template">viewable here</a>) to help data providers create datasets that are ready for ingestion into the FuTRES knowledge base. The field names in the template largely correspond to <a href="https://dwc.tdwg.org/">Darwin Core</a> terms. Since Darwin Core is the most commonly used standard for sharing biodiversity occurrence data, these fields may already be pre-existing in most collections databases, or if not, they can be easily mapped or crosswalked from other existing fields.</p>

### Formatting data

  <p>We have also created a <a href="https://futres.shinyapps.io/pyConvApp/">RShiny App</a> to help users format their data in the correct format for uplad to <a href="https://geome-db.org/">GEOME</a>. You can read more about the RShiny App <a href="https://github.com/futres/RShinyFuTRES/blob/main/README.md ">here</a> and how to contribute data <a href="https://futres.org/data_tutorial/">here</a>.</p>
 
<h1><img src="/media/ontologyIcon.png"
width="100"
style="float:left;">
  
## Reasoning

### Ontology

<p>An ontology is a knowledge representation which describes concepts and their relationships to one another in a logical framework that is understandable by machines. The benefits of using ontologies are:</p>
  
  1. Ontological terms have unique, persistent identifiers and logically defined terms, which aids in standardization and clarity.
  2. The graph-structure (imagine edges and nodes) allow for interence, which aids in discoverability and findability.
  3. The graph-structure also allows for scalability, including increasing template terms and trait terms.
  
  <p>The ontology is used for triplifying and reasoning in the data pipeline.</p>

#### Biological Collections Ontology

<p>The data model relies heavily on the <a href="https://obofoundry.org/ontology/bco.html">Biological Collections Ontology</a>. The classes in the BCO connects the properties (column headers) in the template to the values in the dataset.</p>

#### FuTRES Ontology of Vertebrate Traits

<p>The <a href="https://github.com/futres/fovt">FuTRES Ontology of Vertebrate Traits</a> (FOVT) is an application ontology specifically designed to serve the purposes of the FuTRES projects. It was developed by Dr. Ramona Walls, Dr. Meghan Balk, and Laura Brenskelle, and it reuses many existing ontologies (for example, <a href="https://www.ebi.ac.uk/ols/ontologies/uberon">UBERON</a>, <a href="http://www.obofoundry.org/ontology/pato.html">PATO</a>, <a href="http://www.obofoundry.org/ontology/bspo.html">BSPO</a>, and <a href="https://obofoundry.org/ontology/oba.html">OBA</a>) to create and define vertebrate traits. These become the controlled vocabulary for "measurementType".</p>
  
  <p>Trait terms can be requested <a href="https://github.com/futres/fovt/issues/new">here</a>.</p>

## Data Loading
  
<p>The FuTRES data store serves dataset where each row is a unique measurement (long format). This differs from how researchers may normally collect data, where each row is a specimen. Having each row as a measurement makes it easier for the pipeline as well as for subsequent analyses. Each measurement (row) has a unique diagnosticID. These diagnosticIDs of the same element are connected to each other via materialSampleID. The materialSampleIDs (elements) of the same indiby individualID. As an example, a dataset with four measurements, two from the illium and two from the femur, all belonging to the individual would look like this:</p>

| individualID | materialSampleID | catalogNumber | diagnosticID | scientificName | measurementType | measurementValue | measurementUnit|
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
|1|1|FMNH PR2081|1|<i>Tyrannosaurus rex</i>|illium length|1525|mm|
|1|1|FMNH PR2081|2|<i>Tyrannosaurus rex</i>|illium depth|608|mm|
|1|2|FMNH PR2081|3|<i>Tyrannosaurus rex</i>|femur length|1321|mm|
|1|2|FMNH PR2081|4|<i>Tyrannosaurus rex</i>|femur circumference|580|mm|

## Accessing the datastore

### API

<p>The datastore can be accessed through our <a href="https://futres-data-interface.netlify.app/">API</a>, where users can search the datastore and download data.</p>
  
### R Package

<p>The datastore can also be access through the <a href="https://github.com/futres/rfutres/">rfutres</a> package (read more <a href="https://github.com/futres/rfutres/blob/master/README.md">here</a>).</p>
